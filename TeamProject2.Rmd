---
title: "TeamProject2"
author: "Dance Dance Revolution: Mario Prata Dias Alvarez, Sophie Kate Edelman, Meghan Sarah Hoffman, Elias Florentin John, Kritika Singh, Benjamin Victor Tward"
date: "2025-10-23"
output: 
  html_document:
    toc: True
    toc_float: True
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#install.packages("tidyverse")
library(tidyverse)
library(caret)
#install.packages("recipes")
library(recipes)
```

## Step 0: Why?

**Objective:** To maximize user retention and daily active listening time, how can Spotify's recommendation engine use a song's audio features (danceability, energy, valence), track_genre, and other variables to build a predictive model that more accurately identifies high-engagement tracks (i.e., high future popularity) for its personalized playlists like 'Discover Weekly'?

**Assumption:** A 10% increase in the number of high-engagement songs a user hears in their 'Discover Weekly' playlist will lead to a 0.5% decrease in their probability of churning (canceling their subscription) that month.

## Step 1: Load the Data

```{r}
songs <- read.csv("Spotify.csv", stringsAsFactors = T)
```

## Step 2: Clean the Data

```{r}
songs = songs |>
  select(-c(X, track_id, album_name, track_name, artists)) |>
  mutate(popularity = ifelse(popularity > 50, 1, 0))
# If we wanted to incorporate artist popularity, we would not delete artists
# Approach would be GEE with artist groupings, gaussian family for linear outcome (not fully robust but acceptable)
# For now, we can look at naive approach to consider all artists to be equal playing field

songs |> glimpse()
```

## Step 3: Split the Data

```{r}
n = nrow(songs)
p = .7

set.seed(12345)
ind = sample(1:n, n*p)
train = songs[ind,]
test = songs[-ind,]

rec = recipe(popularity ~ ., data = train) |>
  step_impute_median(all_numeric_predictors()) |> 
  step_normalize(all_numeric_predictors()) |>
  step_dummy(all_nominal_predictors())

prep_rec = prep(rec, training = train, retain = FALSE)

X_train = bake(prep_rec, new_data = train, all_predictors())
X_test  = bake(prep_rec, new_data = test, all_predictors())

y_train = train$popularity
y_test  = test$popularity

train = X_train |> mutate(popularity = y_train)
test = X_test |> mutate(popularity = y_test)

```

## Step 4, 5, and 6: The Models

### Logistic Regression

#### Step 4: Build the Model

```{r}
m1 <- glm(popularity ~ ., data = train, family=binomial())
```

#### Step 5: Predict

```{r}
song_pred_log <- predict(m1, test)
song_pred_bin <- ifelse(song_pred_log >= .5, 1, 0)
song_test_bin <- test$popularity

```

#### Step 6: Evaluate the Model

```{r}
lm_confusion <- confusionMatrix(as.factor(song_pred_bin), as.factor(song_test_bin), positive = "1")

lm_confusion
```

**Accuracy:** Our Linear Regression model predicted whether or not a song was popular about `r round((as.numeric(lm_confusion$overall["Accuracy"]) * 100), digits = 2)`% of the time.

**Sensitivity:** Of all the song that were popular, our model identified about `r round((as.numeric(lm_confusion$byClass["Sensitivity"]) * 100), digits = 2)`% of them.

**Specificity:** Of all the songs that were not popular, our model identified about `r round((as.numeric(lm_confusion$byClass["Specificity"]) * 100), digits = 2)`% of them.

### KNN

#### Step 4: Build the Model

#### Step 5: Predict

#### Step 6: Evaluate the Model

### Decision Tree (With and without Cost Matrix)

#### Step 4: Build the Model

#### Step 5: Predict

#### Step 6: Evaluate the Model

### ANN

#### Step 4: Build the Model

#### Step 5: Predict

#### Step 6: Evaluate the Model

## Step 7: Conclusion

### Combined Models

### Overall Conclusion

### Possible Errors
